{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from sklearn.metrics import precision_score,f1_score,confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix,f1_score\n",
    "from pyod.models.knn import KNN \n",
    "from sklearn.model_selection import KFold\n",
    "import hdbscan\n",
    "import seaborn as sns\n",
    "\n",
    "def split_train_test(data):\n",
    "    original_train, original_test = train_test_split(data, train_size=0.8)\n",
    "    return original_train,original_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y pred FROM KNN 0    37000\n",
      "1     4111\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vignesh/.local/lib/python3.6/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    }
   ],
   "source": [
    "def str_to_numeric(Data):\n",
    "\n",
    " label_mapping = {}\n",
    " char_cols = Data.dtypes.pipe(lambda x: x[x == 'object']).index\n",
    " for c in char_cols:\n",
    "    Data[c], label_mapping[c] = pd.factorize(Data[c])\n",
    "\n",
    " return Data\n",
    "\n",
    "def load_data():\n",
    "    #loading the data set from CSV file\n",
    "    data = pd.read_csv(\"/home/vignesh/Documents/MachineLearningProjectTCDVersion2/ML1819--task-102--team-18/com/tcd/vignesh_notebooks/Imputed and Pruned.csv\");\n",
    "    return data\n",
    "\n",
    "def LOF(train_X):\n",
    "    clf=LocalOutlierFactor(n_neighbors=100, metric='minkowski',contamination=0.1)\n",
    "    y_pred = clf.fit_predict(train_X.drop(['id'], axis=1))\n",
    "    outlier=y_pred[y_pred==-1]\n",
    "    inlier=y_pred[y_pred==1]\n",
    "    print('inlier',len(inlier),'outlier',len(outlier),'total train X', len(train_X))\n",
    "    return y_pred\n",
    "\n",
    "def HDBSCAN(train):\n",
    "   train_X = train[train.columns.difference(['id'])]\n",
    "   clusterer = hdbscan.HDBSCAN(min_cluster_size=5, gen_min_span_tree=True)\n",
    "   clusterer.fit(train_X)\n",
    "   y_pred=clusterer.labels_\n",
    "#    print(clusterer.outlier_scores_)\n",
    "#    print('HDBCSACN',pd.Series(clusterer.labels_).value_counts())\n",
    "   return y_pred\n",
    "\n",
    "def KNN_outlier(train):\n",
    "#KNN using pypod\n",
    "   train_X = train[train.columns.difference(['id'])]\n",
    "   clf_name = 'KNN'\n",
    "   clf = KNN()\n",
    "   clf.fit(train_X)\n",
    "   y_train_scores = clf.decision_scores_\n",
    "   y_pred = clf.labels_\n",
    "#    print(y_pred)\n",
    "   print('y pred FROM KNN',pd.Series(y_pred).value_counts())\n",
    "   return y_pred\n",
    "    \n",
    "def Outlier_detection():\n",
    "     #loading the imputed data set from CSV file\n",
    "    train=load_data()\n",
    "    train_copied = train.copy()\n",
    "#     train,test=split_train_test(data)\n",
    "     #splitting the dataset into train and test\n",
    "    train = str_to_numeric(train)\n",
    "    train_X = train[train.columns.difference(['y'])]\n",
    "#     train_X = train_X.drop(['id'],axis=1)\n",
    "#     print(len(test))\n",
    "    train_Y = train[['y']]\n",
    "#     kf = KFold(n_splits=5)\n",
    "#     for train_index, test_index in kf.split(train_X):\n",
    "#        X_train, X_test = train_X.iloc[train_index], train_X.iloc[test_index]\n",
    "#     KNN_outlier(X_train)\n",
    "    \n",
    "    train_copied['outlier'] = KNN_outlier(train_X)\n",
    "    return train_copied\n",
    "    #HDB scan outlier detection\n",
    "#     HDBSCAN(train_X,train_Y)\n",
    "    #KNN detection\n",
    "#     KNN_outlier(train_X, train_Y)\n",
    "    \n",
    "    \n",
    "outlier_train = Outlier_detection()    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>y</th>\n",
       "      <th>id</th>\n",
       "      <th>outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>45</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>no</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>59</td>\n",
       "      <td>admin</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>no</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>41</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>no</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>24</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>no</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>25</td>\n",
       "      <td>services</td>\n",
       "      <td>single</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>no</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          job  marital            education  default housing loan  \\\n",
       "0   56    housemaid  married             basic.4y       no      no   no   \n",
       "1   57     services  married          high.school  unknown      no   no   \n",
       "2   37     services  married          high.school       no     yes   no   \n",
       "3   40        admin  married             basic.6y       no      no   no   \n",
       "4   56     services  married          high.school       no      no  yes   \n",
       "5   45     services  married             basic.9y  unknown      no   no   \n",
       "6   59        admin  married  professional.course       no      no   no   \n",
       "7   41  blue-collar  married             basic.9y  unknown      no   no   \n",
       "8   24   technician   single  professional.course       no     yes   no   \n",
       "9   25     services   single          high.school       no     yes   no   \n",
       "\n",
       "     contact month day_of_week   ...     pdays  previous     poutcome  \\\n",
       "0  telephone   may         mon   ...       999         0  nonexistent   \n",
       "1  telephone   may         mon   ...       999         0  nonexistent   \n",
       "2  telephone   may         mon   ...       999         0  nonexistent   \n",
       "3  telephone   may         mon   ...       999         0  nonexistent   \n",
       "4  telephone   may         mon   ...       999         0  nonexistent   \n",
       "5  telephone   may         mon   ...       999         0  nonexistent   \n",
       "6  telephone   may         mon   ...       999         0  nonexistent   \n",
       "7  telephone   may         mon   ...       999         0  nonexistent   \n",
       "8  telephone   may         mon   ...       999         0  nonexistent   \n",
       "9  telephone   may         mon   ...       999         0  nonexistent   \n",
       "\n",
       "  emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m   y id  outlier  \n",
       "0          1.1          93.994          -36.4      4.857  no  0        0  \n",
       "1          1.1          93.994          -36.4      4.857  no  1        0  \n",
       "2          1.1          93.994          -36.4      4.857  no  2        0  \n",
       "3          1.1          93.994          -36.4      4.857  no  3        0  \n",
       "4          1.1          93.994          -36.4      4.857  no  4        0  \n",
       "5          1.1          93.994          -36.4      4.857  no  5        0  \n",
       "6          1.1          93.994          -36.4      4.857  no  6        0  \n",
       "7          1.1          93.994          -36.4      4.857  no  7        0  \n",
       "8          1.1          93.994          -36.4      4.857  no  8        0  \n",
       "9          1.1          93.994          -36.4      4.857  no  9        0  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_train[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_numeric(data):\n",
    "    data1 = data.copy()\n",
    "    label_mapping = {}\n",
    "    char_cols = data1.dtypes.pipe(lambda x: x[x == 'object']).index\n",
    "    for c in char_cols:\n",
    "       data1[c], label_mapping[c] = pd.factorize(data1[c])\n",
    "    return data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLModel(trainX,trainY,testX,clf):\n",
    "    clf.fit(trainX,trainY)\n",
    "    return clf.predict(testX)\n",
    "    \n",
    "\n",
    "def KFoldValidation(train_X,train_Y,clf,k):\n",
    "    kf = StratifiedKFold(n_splits=6)\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    for train_index, test_index in kf.split(pruned_train_X,pruned_train_Y):\n",
    "        X_train, X_test = pruned_train_X.iloc[train_index], pruned_train_X.iloc[test_index]\n",
    "        y_train, y_test = pruned_train_Y.iloc[train_index], pruned_train_Y.iloc[test_index]\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test) \n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        specificity = tn / (tn+fp) \n",
    "        print(\"specificity = \",specificity) \n",
    "        print(\"precision = \",precision_score(y_test, y_pred))\n",
    "        print(\"f1 score = \",f1_score(y_test, y_pred)) \n",
    "        print(\"recall = \",recall_score(y_test, y_pred)) \n",
    "        print(\"yes \",len(y_test[y_test==1]),\" no \",len(y_test[y_test==0]))\n",
    "        precision_scores.append(precision_score(y_test, y_pred))\n",
    "        recall_scores.append(recall_score(y_test, y_pred))\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"average precision = \",np.mean(np.array(precision_scores)))\n",
    "    print(\"average recall = \",np.mean(np.array(recall_scores)))\n",
    "    print(\"sd precision = \",np.mean(np.std(precision_scores)))\n",
    "    print(\"sd recall = \",np.mean(np.std(recall_scores)))\n",
    "    \n",
    "def evaluateTestData(y_test, y_pred):\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        specificity = tn / (tn+fp) \n",
    "        print(\"specificity = \",specificity) \n",
    "        print(\"precision = \",precision_score(y_test, y_pred))\n",
    "        print(\"f1 score = \",f1_score(y_test, y_pred)) \n",
    "        print(\"recall = \",recall_score(y_test, y_pred))\n",
    "        print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_job(job):\n",
    "    job_copied = job.copy()\n",
    "    job_copied[job_copied=='housemaid']=0\n",
    "    job_copied[job_copied=='services']=1\n",
    "    job_copied[job_copied=='admin']=2\n",
    "    job_copied[job_copied=='blue-collar']=3\n",
    "    job_copied[job_copied=='technician']=4\n",
    "    job_copied[job_copied=='retired']=5\n",
    "    job_copied[job_copied=='management']=6\n",
    "    job_copied[job_copied=='unemployed']=7\n",
    "    job_copied[job_copied=='self-employed']=8\n",
    "    job_copied[job_copied=='entrepreneur']=9\n",
    "    job_copied[job_copied=='student']=10\n",
    "    job_copied[job_copied=='unknown']=11\n",
    "    return job_copied\n",
    "\n",
    "def encode_marital(marital):\n",
    "    marital_copied = marital.copy()\n",
    "    marital_copied[marital_copied=='married']=0\n",
    "    marital_copied[marital_copied=='single']=1\n",
    "    marital_copied[marital_copied=='divorced']=2\n",
    "    marital_copied[marital_copied=='unknown']=3\n",
    "    return marital_copied\n",
    "\n",
    "def encode_education(education):\n",
    "    education_copied = education.copy()\n",
    "    education_copied[education_copied=='basic.4y']=0\n",
    "    education_copied[education_copied=='high.school']=1\n",
    "    education_copied[education_copied=='basic.6y']=2\n",
    "    education_copied[education_copied=='basic.9y']=3\n",
    "    education_copied[education_copied=='professional.course']=4\n",
    "    education_copied[education_copied=='university.degree']=5\n",
    "    education_copied[education_copied=='illiterate']=6\n",
    "    education_copied[education_copied=='unknown']=7\n",
    "    return education_copied\n",
    "\n",
    "def encode_month(month):\n",
    "    month_copied = month.copy()\n",
    "    month_copied[month_copied=='jan']=0\n",
    "    month_copied[month_copied=='feb']=1\n",
    "    month_copied[month_copied=='mar']=2\n",
    "    month_copied[month_copied=='apr']=3\n",
    "    month_copied[month_copied=='may']=4\n",
    "    month_copied[month_copied=='jun']=5\n",
    "    month_copied[month_copied=='jul']=6\n",
    "    month_copied[month_copied=='aug']=7\n",
    "    month_copied[month_copied=='sep']=8\n",
    "    month_copied[month_copied=='oct']=9\n",
    "    month_copied[month_copied=='nov']=10\n",
    "    month_copied[month_copied=='dec']=11\n",
    "    return month_copied\n",
    "\n",
    "def encode_day_of_week(day_of_week):\n",
    "    day_of_week_copied = day_of_week.copy()\n",
    "    day_of_week_copied[day_of_week_copied=='mon']=0\n",
    "    day_of_week_copied[day_of_week_copied=='tue']=1\n",
    "    day_of_week_copied[day_of_week_copied=='wed']=2\n",
    "    day_of_week_copied[day_of_week_copied=='thu']=3\n",
    "    day_of_week_copied[day_of_week_copied=='fri']=4\n",
    "    return day_of_week_copied\n",
    "\n",
    "def encode_poutcome(poutcome):\n",
    "    poutcome_copied = poutcome.copy()\n",
    "    poutcome_copied[poutcome_copied=='nonexistent']=0\n",
    "    poutcome_copied[poutcome_copied=='failure']=1\n",
    "    poutcome_copied[poutcome_copied=='success']=2\n",
    "    return poutcome_copied\n",
    "\n",
    "def encode_contact(contact):\n",
    "    contact_copied = contact.copy()\n",
    "    contact_copied[contact_copied=='cellular']=0\n",
    "    contact_copied[contact_copied=='telephone']=1\n",
    "    return contact_copied\n",
    "\n",
    "def encode_binary(binary):\n",
    "    binary_copied = binary.copy()\n",
    "    binary_copied[binary_copied=='no']=0\n",
    "    binary_copied[binary_copied=='yes']=1\n",
    "    binary_copied[binary_copied=='unknown']=2\n",
    "    return binary_copied\n",
    "\n",
    "def encode_binary_rev(binary):\n",
    "    binary_copied = binary.copy()\n",
    "    binary_copied[binary_copied=='no']=1\n",
    "    binary_copied[binary_copied=='yes']=0\n",
    "    binary_copied[binary_copied=='unknown']=2\n",
    "    return binary_copied\n",
    "\n",
    "def normalize(data):\n",
    "    data1 = data.copy()\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(data1)\n",
    "    return scaler.transform(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_full_train(df):\n",
    "    df1 = df.copy()\n",
    "    df1['job'] = encode_job(df['job']).astype('int64')\n",
    "    df1['marital'] = encode_marital(df['marital']).astype('int64')\n",
    "    df1['education'] = encode_education(df['education']).astype('int64')\n",
    "    df1['loan'] = encode_binary(df['loan']).astype('int64')\n",
    "    df1['housing'] = encode_binary(df['housing']).astype('int64')\n",
    "    df1['default'] = encode_binary(df['default']).astype('int64')\n",
    "    df1['poutcome'] = encode_poutcome(df['poutcome']).astype('int64')\n",
    "    df1['contact'] = encode_contact(df['contact']).astype('int64')\n",
    "    df1['month'] = encode_month(df['month']).astype('int64')\n",
    "    df1['day_of_week'] = encode_day_of_week(df['day_of_week']).astype('int64')\n",
    "    df1['y'] = encode_binary(df['y']).astype('int64')\n",
    "    return df1\n",
    "\n",
    "def encode_full_test(df):\n",
    "    df1 = df.copy()\n",
    "    df1['job'] = encode_job(df['job']).astype('int64').astype('int64')\n",
    "    df1['marital'] = encode_marital(df['marital']).astype('int64')\n",
    "    df1['education'] = encode_education(df['education']).astype('int64')\n",
    "    df1['loan'] = encode_binary(df['loan']).astype('int64')\n",
    "    df1['housing'] = encode_binary(df['housing']).astype('int64')\n",
    "    df1['default'] = encode_binary(df['default']).astype('int64')\n",
    "    df1['poutcome'] = encode_poutcome(df['poutcome']).astype('int64')\n",
    "    df1['contact'] = encode_contact(df['contact']).astype('int64')\n",
    "    df1['month'] = encode_month(df['month']).astype('int64')\n",
    "    df1['day_of_week'] = encode_day_of_week(df['day_of_week']).astype('int64')\n",
    "    return df1\n",
    "\n",
    "def add_prefix(df):\n",
    "    df1 = df.copy()\n",
    "    df1['job'] = 'job_'+ df1['job']\n",
    "    df1['marital'] = 'marital_'+ df1['marital']\n",
    "    df1['education'] = 'education_'+ df1['education']\n",
    "    df1['loan'] = 'loan_'+ df1['loan']\n",
    "    df1['housing'] = 'housing_'+ df1['housing']\n",
    "#     df1['default'] = 'default_'+ df1['default']\n",
    "    df1['poutcome'] = 'poutcome_'+ df1['poutcome']\n",
    "    df1['contact'] = 'contact_'+ df1['contact']\n",
    "    df1['month'] = 'month_'+ df1['month']\n",
    "    df1['day_of_week'] = 'day_of_week_'+ df1['day_of_week']\n",
    "    return df1\n",
    "\n",
    "def change_data_type_to_int64(df):\n",
    "    df1 = df.copy()\n",
    "    cols = ['job_admin',\n",
    "       'job_blue-collar', 'job_entrepreneur', 'job_housemaid',\n",
    "       'job_management', 'job_retired', 'job_self-employed', 'job_services',\n",
    "       'job_technician', 'job_unemployed',\n",
    "       'marital_married', 'marital_single', 'education_basic.4y',\n",
    "       'education_basic.6y', 'education_basic.9y', 'education_high.school',\n",
    "       'education_professional.course',\n",
    "       'education_university.degree', 'loan_yes',\n",
    "       'housing_yes', 'poutcome_failure',\n",
    "       'poutcome_success', 'contact_cellular', 'contact_telephone',\n",
    "       'month_apr', 'month_aug', 'month_jul', 'month_jun',\n",
    "       'month_mar', 'month_may', 'month_nov', 'month_oct', 'month_sep',\n",
    "       'day_of_week_mon', 'day_of_week_thu',\n",
    "       'day_of_week_tue', 'day_of_week_wed']\n",
    "    for c in cols:\n",
    "        df1[c] = df1[c].astype('int64')\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_dummy_variables(df):\n",
    "    df1 = df.copy()\n",
    "    df1 = pd.concat([df1,pd.get_dummies(df['job'])],axis=1)\n",
    "    df1 = pd.concat([df1,pd.get_dummies(df['marital'])],axis=1)\n",
    "    df1 = pd.concat([df1,pd.get_dummies(df['education'])],axis=1)\n",
    "    df1 = pd.concat([df1,pd.get_dummies(df['loan'])],axis=1)\n",
    "    df1 = pd.concat([df1,pd.get_dummies(df['housing'])],axis=1)\n",
    "#     df1 = pd.concat([df1,pd.get_dummies(df['default'])],axis=1)\n",
    "    df1 = pd.concat([df1,pd.get_dummies(df['poutcome'])],axis=1)\n",
    "    df1 = pd.concat([df1,pd.get_dummies(df['contact'])],axis=1)\n",
    "    df1 = pd.concat([df1,pd.get_dummies(df['month'])],axis=1)\n",
    "    df1 = pd.concat([df1,pd.get_dummies(df['day_of_week'])],axis=1)\n",
    "#     df1 = pd.concat(df1,pd.get_dummies(df['y']),axis=1)\n",
    "    df1 = df1.drop(['job','marital','education','loan','housing','default','poutcome','contact','month','day_of_week'],axis=1)\n",
    "    return df1\n",
    "\n",
    "def kthdummy(df):\n",
    "    df1 = df.copy()\n",
    "    df1 = df1.drop(['job_student','marital_divorced','education_illiterate','loan_no','housing_no','poutcome_nonexistent','month_dec','day_of_week_fri'],axis=1)\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prunedData = outlier_train\n",
    "testData = pd.read_csv('/home/vignesh/Downloads/Final_dataset_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'job', 'marital', 'education', 'default', 'housing', 'loan',\n",
       "       'contact', 'month', 'day_of_week', 'campaign', 'pdays', 'previous',\n",
       "       'poutcome', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx',\n",
       "       'euribor3m', 'y', 'id', 'outlier'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prunedData.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vignesh/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/vignesh/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/vignesh/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/vignesh/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/vignesh/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/vignesh/.local/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "prunedData['age'] = normalize(prunedData['age'].values.reshape(-1,1))[:,0]\n",
    "prunedData['emp.var.rate'] = normalize(prunedData['emp.var.rate'].values.reshape(-1,1))[:,0]\n",
    "prunedData['cons.price.idx'] = normalize(prunedData['cons.price.idx'].values.reshape(-1,1))[:,0]\n",
    "prunedData['pdays'] = normalize(prunedData['pdays'].values.reshape(-1,1))[:,0]\n",
    "prunedData['campaign'] = normalize(prunedData['campaign'].values.reshape(-1,1))[:,0]\n",
    "\n",
    "\n",
    "testData['age'] = normalize(testData['age'].values.reshape(-1,1))[:,0]\n",
    "testData['emp.var.rate'] = normalize(testData['emp.var.rate'].values.reshape(-1,1))[:,0]\n",
    "testData['cons.price.idx'] = normalize(testData['cons.price.idx'].values.reshape(-1,1))[:,0]\n",
    "testData['pdays'] = normalize(testData['pdays'].values.reshape(-1,1))[:,0]\n",
    "testData['campaign'] = normalize(testData['campaign'].values.reshape(-1,1))[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "prunedData1 = add_prefix(prunedData)\n",
    "prunedData1 = prunedData1[prunedData1['outlier']!=1]\n",
    "prunedData2 = change_dummy_variables(prunedData1)\n",
    "prunedData3 = kthdummy(prunedData2)\n",
    "prunedData4 = change_data_type_to_int64(prunedData3)\n",
    "\n",
    "testData1 = add_prefix(testData)\n",
    "testData2 = change_dummy_variables(testData1)\n",
    "testData3 = kthdummy(testData2)\n",
    "testData4 = change_data_type_to_int64(testData3)\n",
    "testData5 = testData4.drop(testData4.columns[0],axis=1).drop(['id','y'],axis=1)\n",
    "# prunedDataNumeric = encode_full_train(prunedData)\n",
    "# prunedDataNumeric1 = change_dummy_variables(prunedDataNumeric)\n",
    "\n",
    "# testDataNumeric = encode_full_train(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prunedData4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_train_X = prunedData4.drop(['id','y','outlier'],axis=1)\n",
    "pruned_train_Y = encode_binary(prunedData4['y']).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_train_X = pruned_train_X.drop(['loan_yes'],axis=1)\n",
    "testData5 = testData5.drop(['loan_yes'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "clf = LinearSVC(C=0.001, class_weight={1: 0.9, 0: 0.1}, dual=True,\n",
    "     fit_intercept=True, intercept_scaling=1, loss='squared_hinge',\n",
    "     max_iter=1000, multi_class='ovr', penalty='l2', random_state=0,\n",
    "     tol=1e-05, verbose=0)\n",
    "\n",
    "predictedData2 = MLModel(pruned_train_X,pruned_train_Y,testData5,clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "specificity =  1.0\n",
      "precision =  0.0\n",
      "f1 score =  0.0\n",
      "recall =  0.0\n",
      "yes  513  no  5654\n",
      "[[5654    0]\n",
      " [ 513    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vignesh/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/vignesh/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/vignesh/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "specificity =  0.35797665369649806\n",
      "precision =  0.0\n",
      "f1 score =  0.0\n",
      "recall =  0.0\n",
      "yes  513  no  5654\n",
      "[[2024 3630]\n",
      " [ 513    0]]\n",
      "specificity =  0.035550053059780685\n",
      "precision =  0.04013377926421405\n",
      "f1 score =  0.0736196319018405\n",
      "recall =  0.4444444444444444\n",
      "yes  513  no  5654\n",
      "[[ 201 5453]\n",
      " [ 285  228]]\n",
      "specificity =  0.14449946940219313\n",
      "precision =  0.03337330135891287\n",
      "f1 score =  0.06054014863150264\n",
      "recall =  0.3255360623781676\n",
      "yes  513  no  5654\n",
      "[[ 817 4837]\n",
      " [ 346  167]]\n",
      "specificity =  0.024053767244428724\n",
      "precision =  0.08216899534264804\n",
      "f1 score =  0.1514176245210728\n",
      "recall =  0.9629629629629629\n",
      "yes  513  no  5654\n",
      "[[ 136 5518]\n",
      " [  19  494]]\n",
      "specificity =  0.0\n",
      "precision =  0.08304947283049473\n",
      "f1 score =  0.153362288452898\n",
      "recall =  1.0\n",
      "yes  512  no  5653\n",
      "[[   0 5653]\n",
      " [   0  512]]\n",
      "average precision =  0.03978759146604494\n",
      "average recall =  0.4554905782975958\n",
      "sd precision =  0.03385050862899826\n",
      "sd recall =  0.40537477693227536\n"
     ]
    }
   ],
   "source": [
    "KFoldValidation(pruned_train_X,pruned_train_Y,clf,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "specificity =  0.7856044294063365\n",
      "precision =  0.29560384032339565\n",
      "f1 score =  0.4154829545454546\n",
      "recall =  0.6989247311827957\n",
      "[[5108 1394]\n",
      " [ 252  585]]\n"
     ]
    }
   ],
   "source": [
    "evaluateTestData(encode_binary(testData4['y']).astype('int64'),predictedData2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.623259651553017"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score, auc\n",
    "\n",
    "##Computing false and true positive rates\n",
    "fpr, tpr,_=roc_curve(predictedData2,encode_binary(testData4['y']).astype('int64'),drop_intermediate=False)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "##Adding the ROC\n",
    "plt.plot(fpr, tpr, color='red',\n",
    " lw=2, label='ROC curve')\n",
    "##Random FPR and TPR\n",
    "plt.plot([0, 1], [0, 1], color='blue', lw=2, linestyle='--')\n",
    "##Title and label\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC curve')\n",
    "plt.show()\n",
    "auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictedData2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "CValue = [0.001,0.005,0.01,0.05]\n",
    "class_weights = [{1: 0.6, 0: 0.4},{1: 0.7, 0: 0.3},{1: 0.8, 0: 0.2},{1: 0.9, 0: 0.1}]\n",
    "SVMdict = dict(C=CValue,class_weight=class_weights)\n",
    "# logisticDict = dict(maxiter=maxiterations)\n",
    "# grid = GridSearchCV(clf, logisticDict, cv=6, scoring='precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TuneHyperParameters(dictionary,clf,cv,scoring,trainX,trainY,plt):\n",
    "    grid = GridSearchCV(clf, dictionary, cv=6, scoring=scoring)\n",
    "    grid.fit(trainX,trainY)\n",
    "    testrange = range(1,len(grid.error_score)+1)\n",
    "#     grid_validation = [x.mean_validation_score for x in grid.grid_scores_]\n",
    "#     plt.plot(testrange,grid_validation)\n",
    "#     for x in grid.error_score:\n",
    "#         print(x)\n",
    "    print(grid.cv_results_)\n",
    "    print(grid.best_estimator_)\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pruned_train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vignesh/.local/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/vignesh/.local/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/vignesh/.local/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/vignesh/.local/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/vignesh/.local/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/vignesh/.local/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/vignesh/.local/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/vignesh/.local/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/vignesh/.local/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/vignesh/.local/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/vignesh/.local/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/vignesh/.local/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/vignesh/.local/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/vignesh/.local/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/vignesh/.local/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/vignesh/.local/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/vignesh/.local/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/vignesh/.local/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/vignesh/.local/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/vignesh/.local/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/vignesh/.local/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/vignesh/.local/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/vignesh/.local/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/home/vignesh/.local/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([0.29572701, 0.30604911, 0.32782392, 0.36755288, 1.01804082,\n",
      "       1.15486908, 1.2928046 , 1.43607072, 2.22330296, 2.32181752,\n",
      "       2.50430806, 2.73493695, 5.25446848, 5.56083663, 5.2836231 ,\n",
      "       5.44212751]), 'std_fit_time': array([0.03110768, 0.00958595, 0.00708721, 0.00661475, 0.05984136,\n",
      "       0.07533079, 0.07363609, 0.06786991, 0.44875516, 0.31435451,\n",
      "       0.09739473, 0.10421096, 0.19835133, 0.6462194 , 0.19158468,\n",
      "       0.09747134]), 'mean_score_time': array([0.0037028 , 0.00367713, 0.00369875, 0.00376105, 0.00371178,\n",
      "       0.00370169, 0.00363708, 0.00369744, 0.00375414, 0.00367983,\n",
      "       0.00371146, 0.00364097, 0.00397539, 0.00386874, 0.00381696,\n",
      "       0.00386719]), 'std_score_time': array([1.16509760e-04, 1.31202447e-04, 1.42525440e-04, 5.80135001e-05,\n",
      "       2.03096699e-04, 5.52608460e-05, 1.44560651e-04, 2.92544605e-05,\n",
      "       2.48325474e-04, 1.50716104e-04, 1.05388563e-04, 1.37786321e-04,\n",
      "       1.31108615e-04, 1.37423627e-04, 8.93500200e-05, 1.17289375e-04]), 'param_C': masked_array(data=[0.001, 0.001, 0.001, 0.001, 0.005, 0.005, 0.005, 0.005,\n",
      "                   0.01, 0.01, 0.01, 0.01, 0.05, 0.05, 0.05, 0.05],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_class_weight': masked_array(data=[{1: 0.6, 0: 0.4}, {1: 0.7, 0: 0.3}, {1: 0.8, 0: 0.2},\n",
      "                   {1: 0.9, 0: 0.1}, {1: 0.6, 0: 0.4}, {1: 0.7, 0: 0.3},\n",
      "                   {1: 0.8, 0: 0.2}, {1: 0.9, 0: 0.1}, {1: 0.6, 0: 0.4},\n",
      "                   {1: 0.7, 0: 0.3}, {1: 0.8, 0: 0.2}, {1: 0.9, 0: 0.1},\n",
      "                   {1: 0.6, 0: 0.4}, {1: 0.7, 0: 0.3}, {1: 0.8, 0: 0.2},\n",
      "                   {1: 0.9, 0: 0.1}],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'C': 0.001, 'class_weight': {1: 0.6, 0: 0.4}}, {'C': 0.001, 'class_weight': {1: 0.7, 0: 0.3}}, {'C': 0.001, 'class_weight': {1: 0.8, 0: 0.2}}, {'C': 0.001, 'class_weight': {1: 0.9, 0: 0.1}}, {'C': 0.005, 'class_weight': {1: 0.6, 0: 0.4}}, {'C': 0.005, 'class_weight': {1: 0.7, 0: 0.3}}, {'C': 0.005, 'class_weight': {1: 0.8, 0: 0.2}}, {'C': 0.005, 'class_weight': {1: 0.9, 0: 0.1}}, {'C': 0.01, 'class_weight': {1: 0.6, 0: 0.4}}, {'C': 0.01, 'class_weight': {1: 0.7, 0: 0.3}}, {'C': 0.01, 'class_weight': {1: 0.8, 0: 0.2}}, {'C': 0.01, 'class_weight': {1: 0.9, 0: 0.1}}, {'C': 0.05, 'class_weight': {1: 0.6, 0: 0.4}}, {'C': 0.05, 'class_weight': {1: 0.7, 0: 0.3}}, {'C': 0.05, 'class_weight': {1: 0.8, 0: 0.2}}, {'C': 0.05, 'class_weight': {1: 0.9, 0: 0.1}}], 'split0_test_score': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'split1_test_score': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'split2_test_score': array([0.        , 0.        , 0.        , 0.44444444, 0.        ,\n",
      "       0.        , 0.        , 0.40545809, 0.        , 0.        ,\n",
      "       0.        , 0.34697856, 0.        , 0.        , 0.        ,\n",
      "       0.21442495]), 'split3_test_score': array([0.        , 0.        , 0.        , 0.32553606, 0.        ,\n",
      "       0.        , 0.        , 0.16374269, 0.        , 0.        ,\n",
      "       0.        , 0.13450292, 0.        , 0.        , 0.        ,\n",
      "       0.08966862]), 'split4_test_score': array([0.        , 0.        , 0.03898635, 0.96296296, 0.        ,\n",
      "       0.        , 0.01949318, 0.53606238, 0.        , 0.        ,\n",
      "       0.02729045, 0.28849903, 0.        , 0.00974659, 0.03118908,\n",
      "       0.04873294]), 'split5_test_score': array([0.6953125 , 0.92773438, 0.99609375, 1.        , 0.9140625 ,\n",
      "       0.93945312, 0.98242188, 1.        , 0.91601562, 0.93554688,\n",
      "       0.98242188, 1.        , 0.92382812, 0.95117188, 0.98046875,\n",
      "       1.        ]), 'mean_test_score': array([0.1158541 , 0.15458061, 0.17246883, 0.45546115, 0.15230258,\n",
      "       0.1565332 , 0.16694176, 0.35084211, 0.15262801, 0.15588234,\n",
      "       0.16824138, 0.29495864, 0.15392974, 0.16011032, 0.16856575,\n",
      "       0.22542922]), 'std_test_score': array([0.25909965, 0.34570881, 0.36855158, 0.40536596, 0.34061415,\n",
      "       0.35007565, 0.36470412, 0.35113751, 0.34134196, 0.34862004,\n",
      "       0.36418991, 0.34143202, 0.34425319, 0.35373402, 0.36321378,\n",
      "       0.35383994]), 'rank_test_score': array([16, 12,  5,  1, 15, 10,  8,  2, 14, 11,  7,  3, 13,  9,  6,  4],\n",
      "      dtype=int32), 'split0_train_score': array([0.00585023, 0.11622465, 0.38533541, 0.66029641, 0.07410296,\n",
      "       0.24414977, 0.41185647, 0.60374415, 0.10842434, 0.25234009,\n",
      "       0.4099064 , 0.59555382, 0.14235569, 0.2574103 , 0.40600624,\n",
      "       0.58307332]), 'split1_train_score': array([0.02457098, 0.13728549, 0.31513261, 0.7375195 , 0.14352574,\n",
      "       0.25195008, 0.40483619, 0.6723869 , 0.16068643, 0.30343214,\n",
      "       0.4099064 , 0.65561622, 0.20046802, 0.3299532 , 0.41653666,\n",
      "       0.63533541]), 'split2_train_score': array([0.0351014 , 0.05733229, 0.23088924, 0.71099844, 0.08190328,\n",
      "       0.27652106, 0.40912637, 0.66653666, 0.17082683, 0.28432137,\n",
      "       0.43213729, 0.65093604, 0.24687988, 0.31084243, 0.44734789,\n",
      "       0.63143526]), 'split3_train_score': array([0.03237129, 0.10725429, 0.25936037, 0.53042122, 0.16965679,\n",
      "       0.25546022, 0.35374415, 0.51833073, 0.22347894, 0.2925117 ,\n",
      "       0.35959438, 0.50936037, 0.27223089, 0.30850234, 0.38650546,\n",
      "       0.50195008]), 'split4_train_score': array([0.15288612, 0.24102964, 0.33619345, 0.55655226, 0.24414977,\n",
      "       0.29875195, 0.40093604, 0.49336973, 0.25234009, 0.30928237,\n",
      "       0.41341654, 0.475039  , 0.25663027, 0.34828393, 0.42550702,\n",
      "       0.46138846]), 'split5_train_score': array([0.12475634, 0.33723197, 0.47524366, 0.4920078 , 0.27758285,\n",
      "       0.34424951, 0.42495127, 0.49395712, 0.28070175, 0.34385965,\n",
      "       0.4042885 , 0.50487329, 0.25107212, 0.35243665, 0.40155945,\n",
      "       0.50526316]), 'mean_train_score': array([0.06258939, 0.16605972, 0.33369246, 0.6146326 , 0.16515356,\n",
      "       0.27851376, 0.40090841, 0.57472088, 0.19940973, 0.29762455,\n",
      "       0.40487492, 0.56522979, 0.22827281, 0.31790481, 0.41391046,\n",
      "       0.55307428]), 'std_train_score': array([0.05530473, 0.09443838, 0.08077564, 0.09307208, 0.07592717,\n",
      "       0.0345271 , 0.02238061, 0.07651991, 0.05857212, 0.02757147,\n",
      "       0.02205107, 0.07226513, 0.04426689, 0.03177623, 0.01925918,\n",
      "       0.06722246])}\n",
      "LinearSVC(C=0.001, class_weight={1: 0.9, 0: 0.1}, dual=True,\n",
      "     fit_intercept=True, intercept_scaling=1, loss='squared_hinge',\n",
      "     max_iter=1000, multi_class='ovr', penalty='l2', random_state=0,\n",
      "     tol=1e-05, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "grid_ = TuneHyperParameters(SVMdict,clf,6,'recall',pruned_train_X,pruned_train_Y,plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluateTestData(testDataNumeric['y'],predictedData1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
