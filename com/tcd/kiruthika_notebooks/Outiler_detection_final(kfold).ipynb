{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final draft\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import recall_score\n",
    "from pyod.models.knn import KNN \n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "import hdbscan\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import precision_score,f1_score,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_numeric(Data):\n",
    "    label_mapping = {}\n",
    "    char_cols = Data.dtypes.pipe(lambda x: x[x == 'object']).index\n",
    "    for c in char_cols:\n",
    "        Data[c], label_mapping[c] = pd.factorize(Data[c])\n",
    "    return Data\n",
    "\n",
    "dprint('y pred FROM KNN',pd.Series(y_pred).value_counts())ef load_data():    #loading the data set from CSV file\n",
    "    data = pd.read_csv(\"C:/Users/Kiruthika Velusamy/Documents/Machine Learning Assignment/Imputed and Pruned.csv\");\n",
    "    print(len(data))\n",
    "    return data\n",
    "\n",
    "def split_train_test(data):\n",
    "   \n",
    "    original_train, original_test = train_test_split(data, train_size=0.8)\n",
    "    train = str_to_numeric(original_train)\n",
    "    test = str_to_numeric(original_test)\n",
    "    #train data\n",
    "    return train,test\n",
    "    \n",
    "\n",
    "def LOF(train_X):\n",
    "    clf=LocalOutlierFactor(n_neighbors=90, metric='minkowski',contamination=0.1)\n",
    "    y_pred = clf.fit_predict(train_X.drop(['id'], axis=1))\n",
    "    outlier=y_pred[y_pred==-1]\n",
    "    inlier=y_pred[y_pred==1]\n",
    "    print(' WIthout k fold ------------->inlier from LOF',len(inlier),'outlier from LOF',len(outlier),'total train X', len(train_X))\n",
    "    return y_pred\n",
    "        \n",
    "\n",
    "def HDBSCAN(train):\n",
    "    train_X = train[train.columns.difference(['y'])]\n",
    "    train_Y = train[['y']]\n",
    "    clusterer = hdbscan.HDBSCAN(min_cluster_size=10, gen_min_span_tree=True)\n",
    "    clusterer.fit(train_X)\n",
    "    y_pred=clusterer.labels_\n",
    "    print(clusterer.outlier_scores_)\n",
    "    print('HDBCSACN',pd.Series(clusterer.labels_).value_counts(),'len',len(train_X))\n",
    "    return y_pred\n",
    "\n",
    "def KNN_outlier(train): \n",
    "#KNN using pypod\n",
    "    train_X = train[train.columns.difference(['y'])]\n",
    "    train_Y = train[['y']]\n",
    "    clf_name = 'KNN'\n",
    "    clf = KNN()\n",
    "    clf.fit(train_X)\n",
    "    y_train_scores = clf.decision_scores_\n",
    "    y_pred = clf.labels_\n",
    "    print('\\nOn Training Data:y pred FROM KNN',pd.Series(y_pred).value_counts())\n",
    "    \n",
    "\n",
    "def Crossvalidation(train_X,train_Y):\n",
    "    kf = StratifiedKFold(n_splits=8)\n",
    "    for train_index, test_index in kf.split(train_X,train_Y):print('y pred FROM KNN',pd.Series(y_pred).value_counts())        X_train, X_test = train_X.iloc[train_index], train_X.iloc[test_index]\n",
    "        y_train, y_test = train_Y.iloc[train_index], train_Y.iloc[test_index]\n",
    "        clf=LocalOutlierFactor(n_neighbors=90, metric='minkowski',contamination=0.1)\n",
    "        y_pred = clf.fit_predict(X_train.drop(['id'], axis=1))\n",
    "        outlier=y_pred[y_pred==-1]\n",
    "        inlier=y_pred[y_pred==1]\n",
    "        print('inlier from LOF',len(inlier),'outlier from LOF',len(outlier),'total train X', len(train_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kiruthika Velusamy\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2069: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Kiruthika Velusamy\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\Kiruthika Velusamy\\Anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "On Training Data:y pred FROM KNN 0    29599\n",
      "1     3289\n",
      "dtype: int64\n",
      "\n",
      "On Training Data:y pred FROM KNN 0    29599\n",
      "1     3289\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kiruthika Velusamy\\Anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    }
   ],
   "source": [
    "def Outlier_detection():\n",
    "     #loading the imputed data set from CSV file\n",
    "    data=load_data()\n",
    "    train,test=split_train_test(data)\n",
    "    KNN_outlier(train)\n",
    "    train_X = train[train.columns.difference(['y'])]\n",
    "    train_Y = train[['y']]\n",
    "    KNN_outlier(train)\n",
    "#     LOF(train_X)\n",
    "#     Crossvalidation(train_X,train_Y)\n",
    "    \n",
    "Outlier_detection()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
